{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('mgu-lab': conda)",
   "metadata": {
    "interpreter": {
     "hash": "f7380a7a517a3126ea41455c7f9370e55a346de8ff204edab6f6fc84119f7120"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout, LSTM, ConvLSTM2D\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activety types dict:\n",
    "Activety_Types = {'dws':1,'jog':2,'sit':3,'std':4,'ups':5,'wlk':6}        \n",
    "listDict = list(Activety_Types.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv = 'input/A_DeviceMotion_data/dws_1/sub_1.csv'\n",
    "        \n",
    "# df = pd.read_csv(csv, index_col=0, parse_dates=True, date_parser=lambda epoch: pd.to_datetime(int(epoch) * 20, unit='ms'))\n",
    "# df.plot(subplots=True)\n",
    "# plt.show()\n",
    "\n",
    "# desired_index = pd.date_range('1970-01-01', periods=len(df.index), freq='20ms')\n",
    "\n",
    "# df2 = pd.read_csv(csv, index_col=0, parse_dates=True, date_parser=lambda epoch: pd.to_datetime(int(epoch) * 22, unit='ms'))\n",
    "\n",
    "# df2 = df2.asfreq('20ms').interpolate().reindex_like(df)\n",
    "# df2.plot(subplots=True)\n",
    "# plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = 120\n",
    "n_shift = 20\n",
    "def add_batch(values):\n",
    "    for start in range(0, len(values) - n_timesteps, n_shift):\n",
    "        X.append(values[start : start + n_timesteps])\n",
    "        y.append(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data folders:\n",
    "folders = glob('input/A_DeviceMotion_data/*_*')\n",
    "folders = [s for s in folders if \"csv\" not in s]\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "# Load All data:\n",
    "for j  in folders:\n",
    "    csv = glob(j + '/*' )\n",
    "    # Get activity type from folder name\n",
    "    activity = Activety_Types[j[26:29]]\n",
    "\n",
    "    for i in csv:\n",
    "        df = pd.read_csv(i, index_col=0, parse_dates=True, date_parser=lambda epoch: pd.to_datetime(int(epoch) * 20, unit='ms'))\n",
    "\n",
    "        add_batch(df.values)\n",
    "\n",
    "        df_higher_freq = pd.read_csv(i, index_col=0, parse_dates=True, date_parser=lambda epoch: pd.to_datetime(int(epoch) * 18, unit='ms'))\n",
    "        df_higher_freq = df_higher_freq.asfreq('20ms').interpolate().reindex_like(df).dropna()\n",
    "        \n",
    "        add_batch(df_higher_freq.values)\n",
    "\n",
    "        df_lower_freq = pd.read_csv(i, index_col=0, parse_dates=True, date_parser=lambda epoch: pd.to_datetime(int(epoch) * 22, unit='ms'))\n",
    "        df_lower_freq = df_lower_freq.asfreq('20ms').interpolate().reindex_like(df)\n",
    "        \n",
    "        add_batch(df_lower_freq.values)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('test/*')\n",
    "\n",
    "X = list()\n",
    "y = list()\n",
    "\n",
    "# Load test data:\n",
    "for j  in folders:\n",
    "    csv = glob(j + '/*' )\n",
    "    # Get activity type from folder name\n",
    "    activity = Activety_Types[j[5:8]]\n",
    "\n",
    "    for i in csv:\n",
    "        df = pd.read_csv(i, index_col=0)\n",
    "        add_batch(df.values)\n",
    "\n",
    "X_test_new = np.array(X)\n",
    "y_test_new = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for i in range(X_train.shape[-1]):\n",
    "    scalers[i] = preprocessing.StandardScaler()\n",
    "    X_train[:, :, i] = scalers[i].fit_transform(X_train[:, :, i]) \n",
    "\n",
    "for i in range(X_test.shape[-1]):\n",
    "    X_test[:, :, i] = scalers[i].transform(X_test[:, :, i])\n",
    "\n",
    "for i in range(X_test_new.shape[-1]):\n",
    "    X_test_new[:, :, i] = scalers[i].transform(X_test_new[:, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# zero-offset class values\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "y_test_new = y_test_new - 1\n",
    "# one hot encode y\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_test_new = to_categorical(y_test_new)\n",
    "\n",
    "# Shape of X: [samples, time steps, features]\n",
    "n_features, n_outputs = X_train.shape[2], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "n_steps, n_length = 4, 30\n",
    "X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_steps, 1, n_length, n_features))\n",
    "X_test_new = X_test_new.reshape((X_test_new.shape[0], n_steps, 1, n_length, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x216c590d1c8>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "verbose, epochs, batch_size = 0, 15, 64\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(ConvLSTM2D(16, \n",
    "                                       kernel_size = (1, 3),\n",
    "                                       activation='relu',\n",
    "                                       input_shape=(n_steps, 1, n_length, n_features),\n",
    "                                       return_sequences = True)))\n",
    "model.add(Bidirectional(ConvLSTM2D(32, \n",
    "                                       kernel_size = (3, 3),\n",
    "                                       padding = 'same',\n",
    "                                       return_sequences = True)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[ 4379     7     0     0    41    16]\n [   24  4624     0     0    13     4]\n [    0     0 12081     0     0     0]\n [    3     0     0 10826     0     0]\n [   93     2     0     0  5232    44]\n [   22     0     0     3    26 12290]], shape=(6, 6), dtype=int32)\n0.9940076412628193\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size, use_multiprocessing=True)\n",
    "y_pred_max = tf.argmax(y_pred, axis=1)\n",
    "y_test_max = tf.argmax(y_test, axis=1)\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(y_test_max, y_pred_max, n_outputs)\n",
    "score = accuracy_score(y_test_max, y_pred_max)\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n[[89  0  0  0 23 16]\n [ 0  0  0  0  0  0]\n [11  3 80  0  6  0]\n [ 0  0  0 32  0  0]\n [ 6  0  0  0 98  9]\n [68  2 17  0 85 63]], shape=(6, 6), dtype=int32)\n0.5953947368421053\n"
     ]
    }
   ],
   "source": [
    "y_pred_new = model.predict(X_test_new, batch_size, use_multiprocessing=True)\n",
    "y_pred_new_max = tf.argmax(y_pred_new, axis=1)\n",
    "y_test_new_max = tf.argmax(y_test_new, axis=1)\n",
    "\n",
    "confusion_matrix = tf.math.confusion_matrix(y_test_new_max, y_pred_new_max, n_outputs)\n",
    "score = accuracy_score(y_test_new_max, y_pred_new_max)\n",
    "\n",
    "print(confusion_matrix)\n",
    "print(score)"
   ]
  }
 ]
}